{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "This data pipeline scrappes raw data from [joburgmarket](http://www.joburgmarket.co.za/dailyprices.php) to an SQL Database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import urllib\n",
    "from scrapy.http import HtmlResponse\n",
    "from sqlalchemy import create_engine, insert, Table, MetaData, select\n",
    "\n",
    "# Custom upload with connection string\n",
    "from engine_info import server_info\n",
    "# From tables.py\n",
    "import tables\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Url where the data is going to be scrapped from\n",
    "url = 'http://www.joburgmarket.co.za/dailyprices.php'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting html content of the url\n",
    "html = requests.get(url).content\n",
    "# Creating a response variable to enable web scrapping in the url \n",
    "response = HtmlResponse(url=url, body=html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the date for latest information displayed on the website\n",
    "date = response.xpath('//div[@id=\"right2\"]').css('p b ::text').get()\n",
    "print(f\"The latest information in the Joburg market website is for {date}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a connection to MS SQL SERVER\n",
    "params = urllib.parse.quote_plus(server_info)\n",
    "engine = create_engine('mssql+pyodbc:///?odbc_connect=%s' % params)\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what is in the database\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scrapping_date update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = MetaData(bind=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates from the sql date table\n",
    "scrapped_dates = Table('Joburg_Fresh_produce_scrapping_date', metadata, autoload=True, autoload_engine=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = select([scrapped_dates.columns.date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_dates = connection.execute(stmt).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latest date in the SQL database\n",
    "sql_dates[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the data in the database is up to date\n",
    "if date == sql_dates[-1][0]:\n",
    "    print(\"Warning!!! The date is already in the database, this will create duplicated data in the database.\")\n",
    "else:\n",
    "    date_df = pd.DataFrame([date], columns=[tables.ScrappingDates.__table__.columns.keys()[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer dataframe to sql table\n",
    "date_df.to_sql('Joburg_Fresh_produce_scrapping_date', con=engine, index=False, if_exists='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## commodity_raw update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data scrapped comes in as a list, which must be converted to a Dataframe\n",
    "commodity_df = pd.read_html(url)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commodity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach the date column to the dataframe\n",
    "commodity_df.insert(loc=0, column='Date', value=date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commodity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The commodity_df must be transfered to commodity_raw sql database.\n",
    "# Rename the column names in DataFrame to match column names in SQL table\n",
    "commodity_df.columns = tables.Commodity.__table__.columns.keys()[1:] # Exclude the id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commodity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer dataframe to sql table\n",
    "commodity_df.to_sql('commodity_raw', con=engine, index=False, if_exists='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## container_raw update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract value that links it to the commodity website for a detailed stats\n",
    "commodity_values = response.xpath('//select/option/@value').extract()[1:] # Exclude 'All' option\n",
    "# Extract commodity name\n",
    "commodity_names = response.xpath('//table[@class=\"alltable\"]').css('td.tleft2 ::text').extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, (name, value) in enumerate(zip(commodity_names, commodity_values)):\n",
    "    # URL for container information which will update value for each commodity\n",
    "    url_one = f'http://www.joburgmarket.co.za/dailyprices.php?commodity={value}&containerall=1'\n",
    "    \n",
    "    # Initially create a DataFrame \n",
    "    if not index:\n",
    "        \n",
    "        container_df = pd.read_html(url_one)[0]\n",
    "        # Attach the commodity name column to the container dataframe\n",
    "        container_df.insert(loc=0, column='commodity', value=name)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # Create a temporary DataFrame\n",
    "        temp_df = pd.read_html(url_one)[0]\n",
    "        # Attach the commodity name column to the temporary dataframe\n",
    "        temp_df.insert(loc=0, column='commodity', value=name)\n",
    "        # Concatenate temporary DataFrame to the container DataFrame\n",
    "        container_df = pd.concat([container_df, temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach the date column to the dataframe\n",
    "container_df.insert(loc=0, column='Date', value=date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The container_df must be transfered to container_raw sql database.\n",
    "# Rename the column names in DataFrame to match column names in SQL table\n",
    "container_df.columns = tables.Container.__table__.columns.keys()[1:] # Exclude the id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer dataframe to sql table\n",
    "container_df.to_sql('Joburg_Fresh_produce_container_raw', con=engine, index=False, if_exists='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## product_combination_raw update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, (name, value) in enumerate(zip(commodity_names, commodity_values)):\n",
    "    # URL for container information which will update value for each commodity\n",
    "    url_two = f'http://www.joburgmarket.co.za/dailyprices.php?commodity={value}&containerall=2'\n",
    "    \n",
    "    # Initially create a DataFrame \n",
    "    if not index:\n",
    "        \n",
    "        product_combo_df = pd.read_html(url_two)[0]\n",
    "        # Attach the commodity name column to the product_combo dataframe\n",
    "        product_combo_df.insert(loc=0, column='commodity', value=name)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # Create a temporary DataFrame\n",
    "        temp_df = pd.read_html(url_two)[0]\n",
    "        # Attach the commodity name column to the temporary dataframe\n",
    "        temp_df.insert(loc=0, column='commodity', value=name)\n",
    "        # Concatenate temporary DataFrame to the product_combo DataFrame\n",
    "        product_combo_df = pd.concat([product_combo_df, temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_combo_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach the date column to the dataframe\n",
    "product_combo_df.insert(loc=0, column='Date', value=date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_combo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The container_df must be transfered to container_raw sql database.\n",
    "# Rename the column names in DataFrame to match column names in SQL table\n",
    "product_combo_df.columns = tables.ProductCombination.__table__.columns.keys()[1:] # Exclude the id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_combo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer dataframe to sql table\n",
    "product_combo_df.to_sql('Joburg_Fresh_produce_product_combination_raw', con=engine, index=False, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
